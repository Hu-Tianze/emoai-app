# main.py
import re
import json

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
from config import client
from state import (
    user_prefs, indexes, emotion_memory, average_emotion, global_tone_and_temp
)
import utils
import emotion_module
import rag_module
import agent_module
import meta_module
import datetime

# --- åœ¨ç¨‹åºå¯åŠ¨æ—¶ï¼Œæ‰§è¡Œä¸€æ¬¡ç´¢å¼•åŠ è½½ ---
rag_module.load_and_init_indexes()

# 9. ä¸»å¯¹è¯å‡½æ•° chat_fn()
def chat_fn(user_input, chat_history, tone=0.6, agent_override=None,emotion_history=None):
    if not user_input or not str(user_input).strip():
        yield chat_history, "I'm hearing.", None, ""
        return

    # ==============================================================
    # Metaé€šé“æ£€æµ‹ï¼š
    # ==============================================================
    meta_mode = False
    meta_key, meta_meaning = meta_module.detect_meta_feedback(user_input)
    if meta_key:
        meta_mode = True
        # (è¿™é‡Œæ˜¯æ›´æ–° state.user_prefs çš„é€»è¾‘)
        if "short" in meta_key: user_prefs["reply_length"] = "short"
        elif "long" in meta_key: user_prefs["reply_length"] = "long"
        elif "formal" in meta_key: user_prefs["tone"] = "formal"
        elif "casual" in meta_key: user_prefs["tone"] = "casual"
        print(f"ğŸ§­ å·²æ£€æµ‹åˆ°Metaåé¦ˆï¼š{meta_meaning}ï¼Œæ›´æ–°åå¥½ â†’ {user_prefs}")

    # --- æƒ…ç»ªè¯†åˆ« (è°ƒç”¨ emotion_module) ---
    prev_val = emotion_history[-1][2] if emotion_history else None
    
    emo, score, adj_val_raw, dimension = emotion_module.detect_emotion(user_input)
    
    emo, adj_val = emotion_module.stable_emotion_fusion(emo, adj_val_raw, score, history=emotion_history, meta_mode=meta_mode)
    
    emotion_history.append((user_input, emo, adj_val))
    
    trend = None
    if len(emotion_history) >= 2:
        diff = emotion_history[-1][2] - emotion_history[-2][2]
        trend = "up" if diff > 0.05 else "down" if diff < -0.05 else "stable"

    # --- æ„å›¾è¯†åˆ« (è°ƒç”¨ emotion_module) ---
    intent = emotion_module.detect_intent(user_input)

    # --- Agent è·¯ç”± (è°ƒç”¨ agent_module) ---
    #agent = agent_module.choose_agent_gen3(emo, intent, adj_val, score, prev_val)
    if agent_override and agent_override in agent_module.AGENTS:
        agent = agent_override
        print(f"ğŸ¤– Agent override: ä½¿ç”¨å‰ç«¯æŒ‡å®šçš„ '{agent}'")
    else:
        agent = agent_module.choose_agent_gen3(emo, intent, adj_val, score, prev_val)
        print(f"ğŸ¤– Auto-router: è‡ªåŠ¨é€‰æ‹© '{agent}'")
        
    # --- RAG æ£€ç´¢ (è°ƒç”¨ rag_module, ä½¿ç”¨ state.indexes) ---
    if agent == "counselor":
        index, corpus = indexes["counsel_agent"]
        context = rag_module.retrieve_context(index, corpus, user_input, k=3)
        color = "#ADD8E6"
    elif agent == "funny":
        context = ""
        color = "#FFD580"
    else:
        index, corpus = indexes["empathy_agent"]
        context = rag_module.retrieve_context(index, corpus, user_input, k=3)
        color = "#FFB6C1"

    # --- å…¨å±€è¯­æ°”/æ¸©åº¦ (è°ƒç”¨ state ä¸­çš„å‡½æ•°) ---
    emotion_memory.append({"text": user_input, "emo": emo, "val": adj_val})
    tone_hint, temp = global_tone_and_temp()

    # --- Prompt æ„é€  (è°ƒç”¨ agent_module) ---
    persona = agent_module.build_global_persona(user_prefs)
    # ä¼  user_input="" å› ä¸º agent_module ä¸å†éœ€è¦
    agent_instructions = agent_module.build_prompt(agent, context, "", global_tone_hint=tone_hint, prefs=user_prefs)
    
    system_prompt = persona + "\n\n" + agent_instructions

    # 2. å‡†å¤‡å‘é€ç»™ LLM çš„æ¶ˆæ¯åˆ—è¡¨
    messages_for_llm = [{"role": "system", "content": system_prompt}]
    
    # 3. æ·»åŠ *å·²æœ‰çš„*å¯¹è¯å†å²
    messages_for_llm.extend(chat_history) 
        
    # 4. æ·»åŠ *æœ€æ–°çš„*ç”¨æˆ·è¾“å…¥
    messages_for_llm.append({"role": "user", "content": utils.safe_text(user_input)})
    
    chat_history.append({"role":"user","content":user_input})
    chat_history.append({"role":"assistant","content":""}) 
    # --- æµå¼ç”Ÿæˆ (ä½¿ç”¨ config.client) ---
    report_placeholder = f"**Emotion:** {emotion_module.EMOJI_MAP.get(emo,'â”')} {emo} ({score:.2f}) | **Trend:** {trend or 'â€”'} | **Agent:** <span style='color:{color}'>{agent.capitalize()} (Generating...)</span> | **Avg Valence:** {average_emotion():+.2f}"
    yield chat_history, report_placeholder, None, ""

    reply = ""
    try:
        stream = client.chat.completions.create(
            model="meta/llama-3.1-8b-instruct",
            messages=messages_for_llm,
            temperature=temp,
            max_tokens = 200 if user_prefs.get("reply_length") == "short" else 512,
            stream=True
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                reply += chunk.choices[0].delta.content
                chat_history[-1]["content"] = reply
                yield chat_history, report_placeholder, None, ""

    except Exception as e:
        reply = f"LLM è°ƒç”¨å¤±è´¥ï¼š{e}"
        print(reply)
        chat_history[-1]["content"] = reply # ç¡®ä¿é”™è¯¯ä¿¡æ¯è¢«è®¾ç½®
        # å³ä½¿å‡ºé”™ï¼Œä¹Ÿåº”è¯¥ yield ä¸€æ¬¡æ¥ç»“æŸå‰ç«¯çš„ç­‰å¾…
        # (åœ¨ app.py çš„ stream é€»è¾‘ä¸­å·²ç»å¤„ç†äº†)
        
        
    # --- 3. æ·»åŠ æ—¥å¿—è®°å½• ---
    try:
        log_entry = {
            "timestamp": datetime.datetime.now().isoformat(),
            "user_input": user_input,
            "emotion": emo, #åŸå§‹æƒ…ç»ª
            "emotion_dimension": dimension, # å…­ç»´åº¦æ ‡ç­¾
            "valence": adj_val, # æƒ…ç»ªå€¼
            "trend": trend,     # æƒ…ç»ªè¶‹åŠ¿
            "agent_used": agent,
            "ai_reply": reply   # AI çš„æœ€ç»ˆå›å¤
        }
        utils.log_emotion_entry(log_entry)
    except Exception as e:
        print(f"âŒ æ— æ³•ç»„è£…æ—¥å¿—æ¡ç›®: {e}")
    # --- æ—¥å¿—è®°å½•ç»“æŸ ---
    
    
    # --- å¥–åŠ±æ›´æ–° (è°ƒç”¨ agent_module) ---
    should_update_reward = False
    #åˆ¤æ–­æ˜¯ä¸æ˜¯é’ˆå¯¹æ¨¡å‹æœ¬èº«çš„æ„è§
    if not meta_mode:
        if emo.lower() != "neutral":
            if prev_val is None or abs(adj_val - (prev_val or 0)) > 0.05:
                should_update_reward = True
    # ... (å¥–åŠ±æ›´æ–°çš„åˆ¤æ–­é€»è¾‘) ...
    if should_update_reward:
        last_reply = reply # reply å·²ç»æ˜¯æœ€ç»ˆå›å¤äº†
        agent_module.update_agent_reward(agent, prev_val, adj_val, user_input, last_reply)
    elif meta_mode:
        # --- æƒ…å†µ2: æ˜¯ Meta æ¨¡å¼ -> æ‰§è¡Œ Meta åæ€ ---
        agent_module.update_agent_meta_feedback(agent, user_input, meta_key, meta_meaning)
    else:
        # --- æƒ…å†µ3: é Meta æ¨¡å¼ï¼Œä½†æƒ…ç»ªå˜åŒ–ä¸è¶³ -> è·³è¿‡ ---
        print("ğŸ§  æƒ…ç»ªå¥–åŠ±: è·³è¿‡æ›´æ–°ï¼ˆæƒ…ç»ªå˜åŒ–ä¸è¶³ï¼‰")

    # (è¿™éƒ¨åˆ†åœ¨ app.py çš„æµå¼è¾“å‡ºä¸­å¤„ç†ï¼Œmain.py çš„ chat_fn åªéœ€è¦åœ¨ stream å¾ªç¯ä¸­ yield å³å¯)
    # ...
    # æµå¼ç»“æŸåï¼Œapp.py ä¸­çš„ event_stream() ä¼šè‡ªåŠ¨å‘é€ is_final=True çš„æ¶ˆæ¯
    # æˆ‘ä»¬ä¸éœ€è¦åœ¨è¿™é‡Œä¿®æ”¹ chat_historyï¼Œå› ä¸ºå®ƒåœ¨ stream å¾ªç¯ä¸­å·²ç»è¢«å®æ—¶æ›´æ–°äº†ã€‚
    
    # æœ€åä¸€ä¸ª yield åº”è¯¥åœ¨ app.py çš„ streaming å¾ªç¯ç»“æŸåå¤„ç†
    # æ‰€ä»¥ chat_fn åœ¨ stream å¾ªç¯ç»“æŸåå°±å¯ä»¥æ­£å¸¸ç»“æŸäº†ã€‚
    # app.py ä¸­çš„ä»£ç ä¼šå¤„ç†åç»­çš„ final_report
    
    # ç¡®ä¿æœ€ç»ˆæŠ¥å‘Šè¢«æ›´æ–° (è™½ç„¶ app.py ä¼šæŠ“å–æœ€åä¸€ä¸ª report_placeholderï¼Œä½†æˆ‘ä»¬å¯ä»¥æ›´æ–°å®ƒ)
    final_report = f"**Emotion:** {emotion_module.EMOJI_MAP.get(emo,'â”')} {emo} ({score:.2f}) | **Trend:** {trend or 'â€”'} | **Agent:** <span style='color:{color}'>{agent.capitalize()}</span> | **Avg Valence:** {average_emotion():+.2f}"
    
    # åœ¨ app.py ä¸­ï¼Œfinal_report æ˜¯åœ¨å¾ªç¯å¤–æ•è·çš„ã€‚
    # æˆ‘ä»¬éœ€è¦ç¡®ä¿ stream å¾ªç¯ç»“æŸåï¼Œchat_fn ä¸å† yield
    # (åŸç‰ˆ emoGen3.py çš„ chat_fn æœ€åæœ‰ä¸€ä¸ª returnï¼Œåœ¨ç”Ÿæˆå™¨å‡½æ•°ä¸­è¿™æ˜¯ä¸è§„èŒƒçš„)
    # æˆ‘ä»¬çš„æµå¼å¾ªç¯ç»“æŸåï¼Œå‡½æ•°è‡ªç„¶é€€å‡ºå³å¯ã€‚